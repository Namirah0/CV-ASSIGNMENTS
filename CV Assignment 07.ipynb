{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is the COVARIATE SHIFT Issue, and how does it affect you?\n",
    "Ans:Covariate shift occurs when the distribution of variables in the training data is different to real-world or testing data.\n",
    "    This means that the model may make the wrong predictions once it is deployed, and its accuracy will be significantly lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2563269",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. What is the process of BATCH NORMALIZATION?\n",
    "Ans:It is a process to make neural networks faster and more stable through adding extra layers in a deep neural network. The \n",
    "    new layer performs the standardizing and normalizing operations on the input of a layer coming from a previous layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99548cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Using our own terms and diagrams, explain LENET ARCHITECTURE.\n",
    "Ans:n 1989, Yann LeCun presented a convolutional neural network named LeNet. In general, LeNet refers to LeNet-5 and is a \n",
    "    straightforward convolutional neural network. \n",
    "Convolutional neural networks are a form of feed-forward neural network whose artificial neurons will answer a locality of the\n",
    "encircling cells within the coverage vary and perform well in large-scale image processing.\n",
    "The LeNet-5 means the emergence of CNN and defines the fundamental elements of CNN. However it absolutely was not in style at \n",
    "that point due to the dearth of hardware equipment, particularly GPU (Graphics process Unit, a specialised electronic circuit \n",
    "designed to alter memory to accelerate the creation of pictures during a buffer meant for output to a show device) and \n",
    "different algorithm, appreciate SVM are able to do similar effects or maybe exceed the LeNet.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a55971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Using our own terms and diagrams, explain ALEXNET ARCHITECTURE.\n",
    "Ans:The Alexnet has eight layers with learnable parameters. The model consists of five layers with a combination of max \n",
    "    pooling followed by 3 fully connected layers and they use Relu activation in each of these layers except the output layer.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f085438",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Describe the vanishing gradient problem.\n",
    "Ans:When there are more layers in the network, the value of the product of derivative decreases until at some point the partial\n",
    "    derivative of the loss function approaches a value close to zero, and the partial derivative vanishes. We call this the \n",
    "    vanishing gradient problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e90c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. What is NORMALIZATION OF LOCAL RESPONSE?\n",
    "Ans:The local response normalization layer performs a kind of “lateral inhibition” by normalizing over local input regions. \n",
    "    In ACROSS_CHANNELS mode, the local regions extend across nearby channels, but have no spatial extent (i.e., they have shape\n",
    "    local_size x 1 x 1 )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. In AlexNet, what WEIGHT REGULARIZATION was used?\n",
    "Ans:Weight regularization provides an approach to reduce the overfitting of a deep learning neural network model on the \n",
    "    training data and improve the performance of the model on new data, such as the holdout test set.\n",
    "\n",
    "There are multiple types of weight regularization, such as L1 and L2 vector norms, and each requires a hyperparameter that \n",
    "must be configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0930e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Using our own terms and diagrams, explain VGGNET ARCHITECTURE.\n",
    "Ans:VGG stands for Visual Geometry Group; it is a standard deep Convolutional Neural Network (CNN) architecture with multiple \n",
    "    layers. The “deep” refers to the number of layers with VGG-16 or VGG-19 consisting of 16 and 19 convolutional layers. The \n",
    "    VGG architecture is the basis of ground-breaking object recognition models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e9d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Describe VGGNET CONFIGURATIONS.\n",
    "Ans: VGG stands for Visual Geometry Group; it is a standard deep Convolutional Neural Network (CNN) architecture with multiple\n",
    "    layers. The “deep” refers to the number of layers with VGG-16 or VGG-19 consisting of 16 and 19 convolutional layers. The \n",
    "    VGG architecture is the basis of ground-breaking object recognition models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422163c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. What regularization methods are used in VGGNET to prevent overfitting?\n",
    "Ans:Overfitting of the model occurs when the model learns just ‘too-well’ on the train data. This would sound like an advantage\n",
    "    but it is not. When a model is overtrained on training data, it performs worst on the test data or any new data provided. \n",
    "    Technically, the model learns the details as well as the noise of the train data. This would hinder the performance of any\n",
    "    new data provided to the model as the learned details and noise cannot be applied to the new data. This is the case when we\n",
    "    say the performance of the model is not adequate. There are several ways of avoiding the overfitting of the model such as\n",
    "    K-fold cross-validation, resampling, reducing the number of features, etc. One of the ways is to apply Regularization to \n",
    "    the model. Regularization is a better technique than Reducing the number of features to overcome the overfitting problem \n",
    "    as in Regularization we do not discard the features of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
